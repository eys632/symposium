(이 글에서 말하는 feature distribution은 특징들의 분포를 말하는 것이다.)

딥러닝, autoencoder 등등 많은 기법들이 있는데 이것들은 전부 population을 나타낼 수 있는 함수를 찾는 것임. 이것에 있어 가장 중요한 것은 
population의 일부인 sample dataset을 잘 선정하여 활용해야 한다는 점일 것이다. 그렇다면 선정한 sample dataset의 feature distribution이 실제 population에 feature의 distribution과 
차이가 없어야 비로소 sample dataset을 활용할 수 있을 것이다.

만약 sample dataset의 feature distribution이 population과 다르다면 이후의 어떤 분석, 예측을 하던 의미없는 짓이 되는 것이다.

sample dataset의 feature distribution과 population의 distribution 차이를 측정할 수 있는 방법이 Kullback–Leibler divergence, KLD인 것이다. 

여기서 궁금한, 이해가 되지 않는 생각이 들었다.
population을 완전하게 파악해야 feature distribution을 알 수 있고, 이것이 되어야 sample dataset의 feature distribution가 맞는지 판단할 수 있을 것이다.
그런데 population을 파악하고 있다면 sample dataset을 활용해서 분석, 예측이 필요한가? 라는 생각이다.

예측은 필요없다고 생각이 들지만 분석을 할 때에는 population의 크기가 너무 큰 상황에서 그것을 활용할 수 없기 때문에 sample dataset을 활용한다는 것은 납득이 됨.
